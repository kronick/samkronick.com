<!doctype html>
<head>
    <meta charset="utf-8">
    <link rel="shortcut icon" href="favicon.gif" />
    <link rel="icon" href="favicon.gif" type="image/gif" />
    <meta name="viewport" content="width=device-width, user-scalable=1">
    <title>Sam Kronick - Portfolio</title>
    <link rel="stylesheet" type="text/css" href="css/style.css">
        
    <link rel="shortcut icon" href="favicon.gif" />
    <link rel="icon" href="favicon.gif" type="image/gif" />        
    
    <!-- Google Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
    ga('create', 'UA-12201735-2', 'auto');
    ga('send', 'pageview');
    </script>
    <!-- End Google Analytics -->
            
    <script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
    <script src="js/portfolio.js"></script>
    <script src="js/jquery.transit.min.js"></script>
    <!--<script src="https://use.typekit.net/kmb0nzy.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>-->
    <link rel="stylesheet" href="https://use.typekit.net/egh3zhq.css">

</head>
<body>
<div id="background"></div>
<div id="topBar"></div>
<div id="contents">
    <div id="header">
        <h1>Sam Kronick</h1>
        <div id="contactInfo">
            üì¨&nbsp;<a href="mailto:sam@samkronick.com">sam@samkronick.com</a> 
            üìù&nbsp;<a href="http://www.samkronick.com/resume/">R√©sum√©</a>
        </div>
    </div>
    
    <div id="projectFeature">
    </div>
    <div id="projectGrid">
        <div class="project" data-name="ai-scry">
            üîÆ&nbsp;<a href="#ai-scry" class="headline">Neural network image description in an iPhone app</a>
            <div class="detail">
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/156349334' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>
                
                <h3>Concept</h3>
                <p>
                    Point your camera at the world around you. Harnessing cutting-edge artificial neural network technology, AI ‚Ä¢ Scry (rhymes with "I spy") generates automatic textual descriptions of the objects it sees.
                </p>
                <p>
                    View more about this project at <a href="http://u1f52e.net" target="_blank">http://u1f52e.net/</a>.
                    <br>
                    Press: <a href="http://www.theverge.com/2016/3/10/11187816/neuraltalk-ai-scry-app" target="_blank">The Verge</a>, <a href="http://www.fastcompany.com/3057742/app-economy/meet-the-app-that-uses-a-neural-network-to-describe-the-world" target="_blank">Fast Company</a>, <a href="http://techcrunch.com/2016/03/26/oakland-based-art-and-tech-studio-%F0%9F%92%BE%F0%9F%8C%B5-takes-critical-look-at-a-i/" target="_blank">Tech Crunch</a>, <a href="http://thecreatorsproject.vice.com/blog/ai-scry-neural-network-app" target="_blank">The Creators Project</a> and <a href="http://hyperallergic.com/295923/an-app-turns-the-failures-of-image-recognition-into-whimsical-text/" target="_blank">Hyperallergic</a>.
                </p>
                
                <h3>Technical</h3>
                <p>
                    AI ‚Ä¢ Scry is built on top of Andrej Karpathy's <a href="https://github.com/karpathy/neuraltalk2" target="_blank">neuraltalk2</a> library. To turn that code into a consumer-friendly app that can be downloaded in a single tap I wrote a scalable cloud backend server and an iOS frontend.
                </p>
                <p>
                    On a modern CPU core, neuraltalk2 provides about one caption for an image per second. To get responsiveness that feels like the app is providing captions on a live video feed for even a handful of users at once, I quickly realized I would need to build a scaling load-balanced cluster of servers. Since I expected demand to rise and fall sharply, I chose to do this with Amazon EC2 instances and built a messaging protocol that allowed worker processes to come and go without reconfiguring the whole cluster.
                </p>
                <p>
                    I also built a custom logging and analytics server so I could track spikes in usage, status of worker processes, and overall usage trends. Over 3000 users purchased the app in its first two months, with an overall average of time spent in-app of 7.56 minutes and an average of 4.53 sessions per user. Not bad for a mysterious 99-cent art app with no marketing budget!
                </p>
                <p class="tech">
                    Technologies used: Swift 2, Python, SQLite3, Flask, zeromq, lua, Amazon EC2 
            </div>
        </div>
        
        <div class="project" data-name="vibes">
            üí°&nbsp;<a href="#vibes" class="headline">Consensual Vibes: Tinder for ideas</a>
            <div class="detail">
                <img src="img/consensual-vibes/swipe3.gif">
                
                <h3>Concept</h3>
                <p>
                    Consensual Vibes is a proprietary ideation platform developed for <a href="http://diskcact.us" target="_blank">üíæüåµ ("Disk Cactus") studio</a>. When we started the studio, we recognized the importance of generating a steady flow of unconventional ideas so I invented the Consensual Vibes algorithm to mediate the process.
                </p>
                <p>
                    The process begins by brainstorming words associated loosely with an overall concept or theme. Then, each team member loads the app on their phone. The algorithm randomly sticks two or more words together to create a potential hybrid concept. For each combination, team members can swipe left if they don't like the idea or swipe right if they do. When all team members swipe right on the same concept, it's a match!
                </p>
                <p>
                    Like any good generative system, Consensual Vibes starts with a relatively simple set of rules that create a low barrier to participation, but it winds up creating rich, strange, and captivating ideas that players may never have thought of on their own.
                </p>
                
                <p>
                    The entire experience is mediated by a boombox-like device that contains a wireless router to serve the app, a receipt printer that records matches, and a speaker that announces when a match has been made. The device also acts as the center of a more elaborate ritual designed to escape conventional thinking, initiated with a process of collecting soil from the chosen activity site in a remote setting. See the video below for documentation of the full ritual.
                </p>
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/142207478' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>
                
                <h3>Technical</h3>
                <p>
                    Since the entire experience of using this app is designed to work offline and in the wilderness, the content is served from a small battery-powered WIFI router running OpenWRT contained within the boombox. The router creates a captive portal running a lightweight webapp built with Flask and SQLite. The frontend is built with HTML5/CSS3/Javascript and is served from the OpenWRT router, so it exists independently of any app store.
                </p>
                <p>
                    I designed the device enclosure in Rhino3D and milled it from a solid piece of white maple on a CNC router. I also designed and fabricated PCBs for the audio amplification and LED indicator light electronics. Finally, I designed and fabricated molds for plastic resin-cast accents that give the device additional character.
                </p>
                <img src="img/consensual-vibes/knolled.jpg">
                <p class="tech">
                    Technologies used: OpenWRT, Python, Flask, SQLite3, HTML5, CSS3, Javascript Javascript, jQuery, Rhino3D, RhinoCAM, CNC router, polyurethane resin
                </p>
            </div>
        </div>
        
        <div class="project" data-name="emoji-keyboard">
            ‚ú®&nbsp;<a href="#emoji-keyboard" class="headline">Type emoji on your Mac laptop</a>
            <div class="detail">
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/121100300' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>
                <p>
                üíæüåµüéàüòéüí©‚ù§Ô∏è is the new QWERTY.
                </p>
                <p>
                    When I co-founded üíæüåµ (pronounced "Disk Cactus") studio, I gave it a distinctive and timely name composed solely of two unicode emoji characters (our official LLC paperwork even has us incorporated as U+1F4BE U+1F355, LLC, the longhand representation of the unicode code points for these characters). While most mobile devices today have great support for entering emoji characters, our team realized that a lot of our work and communication with clients was going to take place on a laptop keyboard. To let us type our own name (as well as many of our other favorite emoji), we invented the Emoji Keyboard‚Äî a silicone keyboard overlay and OSX keyboard layout software that turns caps lock into emoji mode.
                </p>
                <p>
                    We launched this product with a <a href="https://www.kickstarter.com/projects/diskcactus/the-emoji-keyboard-type-emoji-on-your-mac" target="_blank">successful Kickstarter campaign</a>, raising over $20,000. <a href="http://www.cosmopolitan.com/lifestyle/news/a37749/kickstarter-emoji-keyboard/" target="_blank">Cosmo</a> called it "the most important Kickstarter campaign of our time" and it is now available from <a href="http://www.amazon.com/Emoji-Keyboard-Silicone-Software-Wireless/dp/B013APKNYE/ref=sr_1_1?ie=UTF8&qid=1464907878&sr=8-1" target="_blank">Amazon.com</a> and <a href="http://www.urbanoutfitters.com/urban/catalog/productdetail.jsp?pid=&id=39211206&catId=A_MUSIC_VITUR" target="_blank">Urban Outfitters</a> (in stores and online).
                </p>
                <img src="img/emoji-keyboard/hands-typing.jpg">
                <img src="img/emoji-keyboard/peel-1.gif">
                <p>
                    More info at <a href="http://emojikeyboard.club" target="_blank">http://emojikeyboard.club</a>
                </p>
            </div>
        </div>

<!--
        <div class="project" data-name="colorbot">
            üêù&nbsp;<a href="#colorbot" class="headline">See the world like a bee or a snake</a>
            <div class="detail">
                <img src="img/colorbot/tara-flower.jpg">
                <p>
                    The <a href="http://calacademy.org/" target="_blank">California Academy of Sciences</a> contacted me and the team at <a href="http://diskcact.us" target="_blank">üíæüåµ</a> to design a project to promote the opening of their new Color of Life exhibit. After working with their marketing team and reading about some of the work that would be in the show, we decided to build a portable version of one of the long-term exhibits. The result was Colorbot: a 
                </p>
                <img src="img/colorbot/jumpsuit.jpg">

            </div>
        </div>
-->
        
        <div class="project" data-name="maker-faire">
            üîä&nbsp;<a href="#maker-faire" class="headline">Can explosions make music?</a>
            <div class="detail">
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/159288103' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>
                <h3>Concept</h3>
                <p>
                    Can explosions make music? This was the brief that <a href="http://weremagnetic.com/">Magnetic</a> handed to <a href="http://diskcact.us" target="_blank">üíæüåµ</a> for <a href="http://www.google.com" target="_blank">Google</a>'s interactive pavilion at <a href="http://makerfaire.com/" target="_blank">Maker Faire</a> 2015. We made it possible with a combination of computer vision tech and a generative music algorithm that mapped exploding confetti particles to pitch and volume of different instruments. With an industrial high speed camera, we turned over 1000 fleeting moments into 1000 unique sound compositions for 1000+ families that stopped by our booth.
                </p>
                <h3>Technical</h3>
                <p>
                    This installation consisted of 3 main components: a camera capture system, a video processing and visualization application, and a generative sound system. I chose to use a <a href="http://ximea.com" target="_blank">XIMEA</a> high framerate industrial camera module because of it's API support. XIMEA provides a C language library that works on OSX and I wrote a wrapper for that to work with the Cinder framework in C++. The video processing is done using OpenCV and Cinder with some help from GLSL shaders. The movement of each individual particle of confetti is tracked, and information from the particles' position and velocity is used to generate OSC control messages that are passed to a Max/MSP patch. The patch then generates a realtime polyphonic soundscape using four different synthetic instruments designed for the activation.
                </p>
                <p>
                    The video below shows the visual software interface with the four different colors of particles separated out.
                </p>
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/159275943' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>
                <p class="tech">
                    Technologies used: Cinder (C/C++), OpenCV (C++), XIMEA industrial camera, Max/MSP, Open Sound Control (OSC)
                </p>
            </div>
        </div>
        
        
        
        <div class="project" data-name="wifi-walkman">
            üåê&nbsp;<a href="#wifi-walkman" class="headline">Listen to WIFI networks as you move through the city</a>
            <div class="detail">
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/156912324' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>
                <h3>Concept</h3>
                <p>
                    The WIFI Walkman is an information sonification device that allows you to hear the presence of invisible WIFI signals that permeate our environment. It is designed to be portable so that a user can experience spatial differences in network density and character. It was produced as an extension of work I did with <a href="http://slowerinternet.com" target="_blank">The Consortium for Slower Internet</a>.
                </p>
                <img src="img/wifiwalkman/wifi-walkman.jpg">
                <h3>Technical</h3>
                <p>
                    The WIFI Walkman is powered by a Raspberry Pi 2. The software scans for WIFI network names, converts the network MAC addresses to a unique sequence of audio tones, and reads the network SSID using text-to-speech software. All the hardware components are packed into a custom enclosure CNC milled from a block of maple wood with resin-cast accents.
                </p>
                <p class="tech">
                    Technologies used: Raspberry Pi, Python, sox, espeak, Rhino3D, RhinoCAM, CNC router, polyurethane resin
                </p>
                <img src="img/wifiwalkman/walkman-knolled.jpg">
                
            </div>
        </div>
        
        <div class="project" data-name="walking-house">
            üè†&nbsp;<a href="#walking-house" class="headline">A robotic house that walks</a>
            <div class="detail">
                <div class='embed-container'><iframe src='https://www.youtube.com/embed/gkb6jfEwe0g' frameborder='0' allowfullscreen></iframe></div>
                <h3>Concept</h3>
                <p>
                    In 2008, I started collaborating with Danish artist collective <a href="http://n55.dk" target="_blank">N55</a>. One of the projects we produced together is the WALKING HOUSE.
                </p>
                <p>
                    WALKING HOUSE is a modular dwelling system that enables persons to live a peaceful nomadic life, moving slowly through the landscape or cityscape with minimal impact on the environment. It collects energy from its surroundings using solar cells and small windmills. There is a system for collecting rain water and a system for solar heated hot water. A small greenhouse unit can be added to the basic living module, to provide a substantial part of the food needed by the Inhabitants. A composting toilet system allows sewage produced by the inhabitants to be disposed of. A small wood burning stove could be added to provide CO2 neutral heating. WALKING HOUSE forms various sizes of communities or WALKING VILLAGES when more units are added together. WALKING HOUSE is not dependent on existing infrastructure like roads, but moves on all sorts of terrain.
                </p>
                <p>
                    The WALKING HOUSE was commissioned by Wysing Arts Center in the U.K. and presented as part of the 2010 European Capital of Culture near Essen, Germany. As part of the latter exhibition, it walked every day in public performances for 100 days. Two friends and I lived inside and maintained the house during the course of exhibition.
                </p>
                <p>
                    More at <a href="http://www.n55.dk/MANUALS/WALKINGHOUSE/walkinghouse.html">N55.dk</a>.
                </p>
                <img src="img/walkinghouse/house-vs-bike.jpg">
                <h3>Technical</h3>
                <p>
                    As part of this collaboration, I was responsible for most of the power systems engineering and software design. The house walks on six fully articulated legs each powered by three electric linear actuators in a tetrahedral arrangement. The whole system is solar powered to be sustainable off the grid.
                </p>
                <p>
                    The unique tetrahedral design of the leg required me to derive custom kinematics equations and write a walking algorithm that would ensure all 18 actuators stayed perfectly synchronized; due to the weight of the house and the strength of the actuators, any mismatch in movement would literally tear the house apart. As part of the system, I designed custom Arduino-based quadrature encoder boards and motor control electronics to handle all 18 channels of motion at once.
                </p>
                <p class="tech">
                    Technologies used: Processing, Arduino, motion control electronics
                </p>
                <img src="img/walkinghouse/ion-on-house.jpg">
            </div>
        </div>
        
        <div class="project" data-name="iheartradio">
            üìª&nbsp;<a href="#iheartradio" class="headline">Live video processing and a CMS for a street-level video wall</a>
            <div class="detail">
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/159281343' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>
                <h3>Concept</h3>
                <p>
                    When I was working with the team at <a href="http://www.sosolimited.com" target="_blank">Sosolimited</a>, I worked on the software that drives a permanent social media-powered LED video wall in the entryway to <a href="http://iheartradio.com/" target="_blank">iHeartRadio</a>'s new concert venue in Burbank, CA. The system we built pulls live tweets about artists and dynamically remixes archival video footage to capture the unique energy of every event. To program and moderate content, the system also has a web-based content management system, so iHeartRadio's staff across the country can be in control.
                </p>
                <h3>Technical</h3>
                <p>
                    iHeartRadio had a lot of unedited, raw footage from past concerts that they wanted to be able to use on this video wall with minimal effort. This meant eliminating most post-production work, so the software we built had to automate some of the basic features of a video editing system like AfterEffects. As a result, all video transitions, graphic overlays, video effects, and the inclusion of social media data are done in realtime using openFrameworks and GLSL shaders. The result is that no matter what quality of content iHeartRadio staff throws at the wall, it always looks pretty good.
                </p>
                <p>
                    Another major challenge for this project was building a web-based CMS frontend that could reliably control the display. Because everything was running on multiple machines and written in multiple languages, I suggested a messaging architecture using RabbitMQ that would ensure all configuration changes and state transitions were kept in sync regardless of whether one piece needed to be restarted independently of the others.
                </p>
                <p class="tech">
                    Technologies used: openFrameworks / C++, GLSL, ffmpeg, Flask, RabbitMQ
                </p>
            </div>
        </div>        
        
        <div class="project" data-name="csis">
            üìä&nbsp;<a href="#csis" class="headline">A DMX-controlled architectural scale data visualization</a>
            <div class="detail">
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/159283757' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>
                <h3>Concept</h3>
                <p>
                    This is another permanent installation I worked on with the team at <a href="http://www.sosolimited.com" target="_blank">Sosolimited</a>. The concept here was to build an architectural-scale data visualization for the <a href="https://www.csis.org/" target="_blank">Center for Strategic and International Studies</a> new headquarters in Washington, DC. The result is a "data chandelier" with 425 independently controlled pendants that form a map of the world when viewed from below. We used this as a canvas to tell stories with data sources relevant to CSIS's work such as GDP growth and global water usage.
                </p>
                <h3>Technical</h3>
                <p>
                    As a permanent installation, a lot of work went into designing and pre-visualizing the final physical form of this work. I developed a number of Processing sketches to experiment with different forms and display resolutions. Initially the resolution of pendants was to be much higher but this had to be reduced for cost reasons; the sketches I made helped determine how low we could go and still have a legible display.
                </p>
                <p>
                    I also wrote Python scripts to process the raw data and turn it into a format that our animation library in openFrameworks could work with. I helped script those animations and wrote a OSX Cocoa UI to adjust parameters and provide a final interface to the installation. The openFrameworks app outputs DMX signals that are then handled by standard lighting hardware integrated into the structure.
                </p>

                <p class="tech">
                    Technologies used: Python, openFrameworks (C++), ofxDMX, Objective C / Cocoa
                </p>
            </div>
        </div>                
        
        <div class="project" data-name="dblcam">
            üëØ&nbsp;<a href="#dblcam" class="headline">This app lets you take two photos at the same time</a>
            <div class="detail">
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/169316845' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>

                <h3>Concept</h3>
                <p>
                    DBLCAM is an iPhone app that lets you take two photos back-to-back using the two cameras on your iPhone. I came up with the idea soon after I heard that the iPhone 4 would add a front-facing camera and learned Objective C and iOS development just to make it happen. Later on I sold the app to <a href="http://socialprintstudio.com" target="_blank">Social Print Studio</a> and to date it has over a million downloads.
                </p>
                <p>
                    Try it out in the <a href="https://itunes.apple.com/us/app/dblcam/id605269890?mt=8" target="_blank">App Store</a> and see how people are using it on <a href="https://www.instagram.com/explore/tags/dblcam/" target="_blank">Instagram</a>.
                </p>

            </div>
        </div>                
        
        <div class="project" data-name="creatorslive">
            üì∑&nbsp;<a href="#creatorslive" class="headline">A realtime interactive photo visualizer for Instagram posts</a>
            <div class="detail">
                <div class='embed-container'>
                    <iframe src='http://player.vimeo.com/video/159274892' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
                </div>
                <h3>Concept</h3>
                <p>
                    Back in 2012, <a href="http://http://thecreatorsproject.vice.com/" target="_blank">The Creators Project</a> approached me and the team at Social Print Studio to build an interactive Instagram visualizer for their art and music festival at Fort Mason in San Francisco. This format of interactive social media display is common now, but at the time it was only recently possible: Instagram had just released their API and the Microsoft Kinect had just  become available.
                </p>
                <h3>Technical</h3>
                <p class="tech">
                    Technologies used: Processing (Java), OpenGL, Microsoft Kinect, Instagram API
                </p>
            </div>
        </div>
        
        <div class="project" data-name="worldwidewest">
            üì°&nbsp;<a href="#worldwidewest" class="headline">World Wide West</a>
            <div class="detail">
                <img src="img/www/trenching-a.jpg">
                <h3>Concept</h3>
                <p>
                    In 2015, I co-founded the first annual World Wide West festival of new media, arts, and digital culture. We invited 25 artists, writers, and technologists from across the country to convene in Point Arena, CA for a weekend of activity and discussions. We wanted to create space for much-needed critical discourse about technology and art in the SF Bay Area.
                </p>
                <p>
                    One of the main activities that I planned was the performative burial of a 350-meter-long fiber optic cable to create a new Internet node in the middle of a field. Participants used shovels to dig a trench for the cable by hand over the course of the event.
                </p>
                <p>
                    In keeping with the theme of exploring internet infrastructure, I also organized a visit to the site of a trans-Pacific submarine fiber optic cable that lands on a beach in Manchester, CA. We invited guests to bring wetsuits and surfboards so we could all literally "surf the web".
                </p>
                <p>
                    World Wide West will return for its second year in the summer of 2016 with an expanded roster of artists. View the <a href="http://worldwidewest.net/2015/" target="_blank">archive from 2015</a> or read about it on <a href="http://hyperallergic.com/226668/welcome-to-world-wide-west-a-summit-on-the-side-effects-of-technology/" target="_blank">Hyperallergic</a>.
                </p>
                <img src="img/www/surf.jpg">
                <img src="img/www/skype-platform.jpg">
                
            </div>
        </div>
       
    </div>

</div>
</body>